# C3. Decision Tree

## Tree Construction 

Information Theory:

1. Information Gain -> Shannon Entropy
2. Gini Impurity

## Steps

1. split the data set by one feature which introduces the least Information Gain
2. form the entire tree by the train set
3. test the tree with test set
4. apply the tree to new incoming data

[Decision Tree in scikit](https://scikit-learn.org/stable/modules/tree.html)